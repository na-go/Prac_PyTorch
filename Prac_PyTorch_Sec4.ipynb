{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prac_PyTorch_Sec4",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdpnlhFEKAzK6fgV9T/zGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/na-go/Prac_PyTorch/blob/master/Prac_PyTorch_Sec4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SR2kwTZne7z",
        "colab_type": "text"
      },
      "source": [
        "# Section4\n",
        "## TOC\n",
        "1. 畳み込みニューラルネットの定義\n",
        "2. 独自画像データセットを畳み込みニューラルネットで分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPg9eq0NnrVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c601f310-7c60-4095-e0a7-84fa127d9d6c"
      },
      "source": [
        "# Google Driveにマウント\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP2LqaGWnwEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62fd249d-233a-4cd7-d30b-4111c64ec0a6"
      },
      "source": [
        "cd gdrive/My Drive/Colab Notebooks/prac_Putorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/prac_Putorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMtkR7iFn3e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モジュールのインポート\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAri_L0tn5FV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1dd3a5d8-f44e-437e-b3a0-d2efe59fc9b4"
      },
      "source": [
        "# データの読み込み\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = \"./data/\",\n",
        "                                             train = True,\n",
        "                                             transform = transforms.ToTensor(),\n",
        "                                             download = True\n",
        "                                             )\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n",
        "                                            train = False,\n",
        "                                            transform = transforms.ToTensor(),\n",
        "                                            download = True\n",
        "                                            )\n",
        "image, label = train_dataset[0]\n",
        "print(image.size())\n",
        "print(label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NUtpzI9n8k-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Dataloaderの定義\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True,\n",
        "                                           num_workers = 2\n",
        "                                           )\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size = 64,\n",
        "                                          shuffle = False,\n",
        "                                          num_workers = 2\n",
        "                                          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRTDWuFan-39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワーク定義\n",
        "num_classes = 10 # 出力数の定義\n",
        "## AlexNetの模倣\n",
        "class AlexNet_trace(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(AlexNet_trace, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
        "        nn.ReLU(inplace =True),\n",
        "        nn.MaxPool2d(kernel_size= 2, stride = 2),\n",
        "        nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.MaxPool2d(kernel_size= 2, stride=2),\n",
        "        nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(384,256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace= True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPUかCPU使用の選択\n",
        "alexnet_trace = AlexNet_trace().to(device) # ネットワーク作成\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # 損失関数としてクロスエントロピーを設定\n",
        "optimizer = optim.SGD(alexnet_trace.parameters(), lr = 0.01, momentum = 0.9, weight_decay=5e-4) # 最適化にSGDを設定"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAv8JKSzrd_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a54ddc9c-76f7-40be-806b-37189e85ea99"
      },
      "source": [
        "# 学習\n",
        "num_epochs = 20 # エポック数の定義, 今回は20\n",
        "\n",
        "## 損失と正解率を保存するリスト\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "eval_loss_list = []\n",
        "eval_acc_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # 損失と正解率の初期化\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  eval_loss = 0\n",
        "  eval_acc = 0\n",
        "\n",
        "  #Trainingモードへ移行=======================\n",
        "  alexnet_trace.train()\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = alexnet_trace(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    train_loss += loss.item()\n",
        "    train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  average_train_loss = train_loss / len(train_loader.dataset)\n",
        "  average_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "  #Evalationモードへ移行======================\n",
        "  alexnet_trace.eval()\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = alexnet_trace(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += (outputs.max(1)[1] == labels).sum().item()\n",
        "\n",
        "  average_eval_loss = eval_loss / len(test_loader.dataset)\n",
        "  average_eval_acc = eval_acc / len(test_loader.dataset)\n",
        "  print(\"Epoch [{}/{}], Loss: {loss:.4f}, eval_loss : {eval_loss:.4f}, eval_acc: {eval_acc:.4f}\".format(epoch+1, num_epochs, i+1, loss = average_train_loss, eval_loss = average_eval_loss, eval_acc = average_eval_acc))\n",
        "  train_loss_list.append(average_train_loss)\n",
        "  train_acc_list.append(average_train_acc)\n",
        "  eval_loss_list.append(average_eval_loss)\n",
        "  eval_acc_list.append(average_eval_acc)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.0277, eval_loss : 0.0251, eval_acc: 0.4117\n",
            "Epoch [2/20], Loss: 0.0236, eval_loss : 0.0222, eval_acc: 0.4789\n",
            "Epoch [3/20], Loss: 0.0212, eval_loss : 0.0202, eval_acc: 0.5323\n",
            "Epoch [4/20], Loss: 0.0196, eval_loss : 0.0208, eval_acc: 0.5196\n",
            "Epoch [5/20], Loss: 0.0181, eval_loss : 0.0186, eval_acc: 0.5752\n",
            "Epoch [6/20], Loss: 0.0168, eval_loss : 0.0177, eval_acc: 0.5936\n",
            "Epoch [7/20], Loss: 0.0156, eval_loss : 0.0179, eval_acc: 0.5985\n",
            "Epoch [8/20], Loss: 0.0144, eval_loss : 0.0170, eval_acc: 0.6230\n",
            "Epoch [9/20], Loss: 0.0132, eval_loss : 0.0168, eval_acc: 0.6293\n",
            "Epoch [10/20], Loss: 0.0122, eval_loss : 0.0172, eval_acc: 0.6317\n",
            "Epoch [11/20], Loss: 0.0113, eval_loss : 0.0177, eval_acc: 0.6194\n",
            "Epoch [12/20], Loss: 0.0102, eval_loss : 0.0188, eval_acc: 0.6107\n",
            "Epoch [13/20], Loss: 0.0094, eval_loss : 0.0184, eval_acc: 0.6158\n",
            "Epoch [14/20], Loss: 0.0086, eval_loss : 0.0187, eval_acc: 0.6333\n",
            "Epoch [15/20], Loss: 0.0078, eval_loss : 0.0192, eval_acc: 0.6410\n",
            "Epoch [16/20], Loss: 0.0070, eval_loss : 0.0204, eval_acc: 0.6194\n",
            "Epoch [17/20], Loss: 0.0063, eval_loss : 0.0202, eval_acc: 0.6371\n",
            "Epoch [18/20], Loss: 0.0056, eval_loss : 0.0212, eval_acc: 0.6303\n",
            "Epoch [19/20], Loss: 0.0051, eval_loss : 0.0233, eval_acc: 0.6205\n",
            "Epoch [20/20], Loss: 0.0048, eval_loss : 0.0228, eval_acc: 0.6237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQbCrnXq6TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 結果の可視化\n",
        "### 損失\n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_loss_list, color=\"blue\", linestyle=\"-\", label=\"train_loss\")\n",
        "plt.plot(range(num_epochs), eval_loss_list, color=\"green\", linestyle=\"--\", label = \"eval_loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"eposh\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Training and Evalidation Loss\")\n",
        "plt.grid()\n",
        "\n",
        "### 正解率\n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_acc_list, color=\"blue\", linestyle=\"-\", label=\"train_acc\")\n",
        "plt.plot(range(num_epochs), eval_acc_list, color=\"green\", linestyle=\"--\", label = \"eval_acc\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"eposh\")\n",
        "plt.ylabel(\"Accurate\")\n",
        "plt.title(\"Traingin and Evalidation Accurate\")\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}